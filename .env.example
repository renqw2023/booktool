# ============================================================
# 小说自动化处理系统 - 环境变量配置示例
# ============================================================
# 使用说明：
# 1. 复制此文件为 .env
# 2. 填入你的真实配置
# 3. 确保 .env 文件不被提交到版本控制（已加入 .gitignore）
# ============================================================

# ------------------------------------------------------------
# LLM API 配置（必需）
# ------------------------------------------------------------
# 你的 LLM API 密钥
LLM_API_KEY=sk-a761ffea7f484aef88be619fb8580f88

# LLM API 基础 URL（阿里云 DashScope）
LLM_BASE_URL=https://dashscope.aliyuncs.com/apps/anthropic

# 默认使用的模型名称
LLM_MODEL=qwen3.5-plus

# ------------------------------------------------------------
# 可选：多模型配置
# ------------------------------------------------------------
# 如果需要使用不同的模型处理不同任务，可以配置以下变量：

# 人物提取专用模型（默认使用 LLM_MODEL）
# EXTRACTOR_MODEL=gpt-4o

# 剧本生成专用模型
# SCRIPT_GENERATOR_MODEL=gpt-4o-mini

# 分镜生成专用模型
# STORYBOARD_GENERATOR_MODEL=gpt-4o-mini

# ------------------------------------------------------------
# 处理配置（可选）
# ------------------------------------------------------------
# 单次处理的最大 Token 数（默认 8000，根据模型上下文窗口调整）
# MAX_TOKENS_PER_CHUNK=8000

# 是否启用记忆合并功能（默认 true）
# ENABLE_MEMORY_MERGE=true

# 是否启用检查点保存（默认 true）
# ENABLE_CHECKPOINT=true

# 检查点保存间隔（每处理 N 个章节保存一次，默认 5）
# CHECKPOINT_INTERVAL=5

# ------------------------------------------------------------
# 输出配置（可选）
# ------------------------------------------------------------
# 输出文件格式：json / yaml / markdown（默认 json）
# OUTPUT_FORMAT=json

# 是否美化输出 JSON（默认 true）
# OUTPUT_INDENT=true

# ------------------------------------------------------------
# 调试配置（可选）
# ------------------------------------------------------------
# 启用详细日志输出（默认 false）
# DEBUG=false

# 是否保存 LLM 请求/响应日志（默认 false）
# LOG_LLM_REQUESTS=false

# 日志文件路径（默认 logs/llm_requests.log）
# LOG_FILE=logs/llm_requests.log
